{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, balanced_accuracy_score\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = pl.read_parquet('dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.with_columns([\n",
    "    pl.col('duration').fill_null(0),\n",
    "    pl.col('orig_bytes').fill_null(0),\n",
    "    pl.col('resp_bytes').fill_null(0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = df_polars.drop([\"ts\", \"uid\", \"id.orig_h\", \"id.resp_h\", \"local_orig\", \"local_resp\", \"missed_bytes\" , \"tunnel_parents\", \"detailed-label\", \"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_polars.drop('label')\n",
    "y = df_polars['label']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular número desejado de características\n",
    "def calculate_desired_num_features(current_num_features):\n",
    "    root = math.sqrt(current_num_features)\n",
    "    desired_num_features = math.ceil(root) ** 2\n",
    "    \n",
    "    return desired_num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_num_features = 16  # 4x4\n",
    "current_num_features = X.shape[1]\n",
    "desired_num_features = calculate_desired_num_features(current_num_features)\n",
    "\n",
    "if current_num_features < desired_num_features:\n",
    "    padding = desired_num_features - current_num_features\n",
    "    X = np.pad(X, ((0, 0), (0, padding)), 'constant')\n",
    "elif current_num_features > desired_num_features:\n",
    "    raise ValueError(\"Número de características é maior que o desejado.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensione os dados\n",
    "SAMPLE_2D_SIZE = 4  # 4x4\n",
    "X_train = X_train.reshape(-1, 1, SAMPLE_2D_SIZE, SAMPLE_2D_SIZE)\n",
    "X_test = X_test.reshape(-1, 1, SAMPLE_2D_SIZE, SAMPLE_2D_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method now of type object at 0x00007FFA9A814FB0>\n",
      "Epoch 1/6, fim em: 2024-09-16 10:24:22.321157\n",
      "Epoch 1/6, avaliada em: 2024-09-16 10:24:24.918744\n",
      "Epoch 2/6, fim em: 2024-09-16 10:24:32.787524\n",
      "Epoch 2/6, avaliada em: 2024-09-16 10:24:35.246079\n",
      "Epoch 3/6, fim em: 2024-09-16 10:24:43.323907\n",
      "Epoch 3/6, avaliada em: 2024-09-16 10:24:45.788464\n",
      "Epoch 4/6, fim em: 2024-09-16 10:24:53.678249\n",
      "Epoch 4/6, avaliada em: 2024-09-16 10:24:56.189817\n",
      "Epoch 5/6, fim em: 2024-09-16 10:25:04.144617\n",
      "Epoch 5/6, avaliada em: 2024-09-16 10:25:06.887238\n",
      "Epoch 6/6, fim em: 2024-09-16 10:25:17.079569\n",
      "Epoch 6/6, avaliada em: 2024-09-16 10:25:20.202598\n"
     ]
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Camadas Convolucionais\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=2, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Camada de Pooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Calcula o tamanho da saída após as camadas convolucionais e de pooling\n",
    "        def conv2d_out_size(size, kernel_size=2, stride=1, padding=0):\n",
    "            return (size - kernel_size + 2 * padding) // stride + 1\n",
    "        \n",
    "        size_after_conv1 = conv2d_out_size(SAMPLE_2D_SIZE, kernel_size=2)\n",
    "        size_after_conv2 = conv2d_out_size(size_after_conv1, kernel_size=2)\n",
    "        size_after_pool = conv2d_out_size(size_after_conv2, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Camada Fully Connected\n",
    "        self.fc1 = nn.Linear(64 * size_after_pool * size_after_pool, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "model = CNNModel(dropout_rate=0.2)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 6\n",
    "results = []\n",
    "print(datetime.now)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{epochs}, fim em: {datetime.now()}')\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    y_pred = (all_preds >= 0.5).astype(int)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, avaliada em: {datetime.now()}')\n",
    "\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    results.append([epoch+1, accuracy, balanced_accuracy, precision, recall, specificity, f1, false_alarm_rate, tn, fp, fn, tp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\miniconda3\\envs\\env-tcc\\lib\\functools.py:889: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (6, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>epoch</th><th>Accuracy</th><th>Balanced Accuracy</th><th>Precision</th><th>Recall</th><th>Specificity</th><th>F1-score</th><th>False Alarm Rate</th><th>tn</th><th>fp</th><th>fn</th><th>tp</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>1</td><td>0.839677</td><td>0.5</td><td>0.839677</td><td>1.0</td><td>0.0</td><td>0.912853</td><td>1.0</td><td>0</td><td>26705</td><td>0</td><td>139865</td></tr><tr><td>2</td><td>0.839677</td><td>0.5</td><td>0.839677</td><td>1.0</td><td>0.0</td><td>0.912853</td><td>1.0</td><td>0</td><td>26705</td><td>0</td><td>139865</td></tr><tr><td>3</td><td>0.839677</td><td>0.5</td><td>0.839677</td><td>1.0</td><td>0.0</td><td>0.912853</td><td>1.0</td><td>0</td><td>26705</td><td>0</td><td>139865</td></tr><tr><td>4</td><td>0.980657</td><td>0.961472</td><td>0.987283</td><td>0.989712</td><td>0.933233</td><td>0.988496</td><td>0.066767</td><td>24922</td><td>1783</td><td>1439</td><td>138426</td></tr><tr><td>5</td><td>0.977241</td><td>0.959681</td><td>0.987343</td><td>0.985529</td><td>0.933833</td><td>0.986435</td><td>0.066167</td><td>24938</td><td>1767</td><td>2024</td><td>137841</td></tr><tr><td>6</td><td>0.976869</td><td>0.959414</td><td>0.987317</td><td>0.985107</td><td>0.93372</td><td>0.986211</td><td>0.06628</td><td>24935</td><td>1770</td><td>2083</td><td>137782</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (6, 12)\n",
       "┌───────┬──────────┬───────────────────┬───────────┬───┬───────┬───────┬──────┬────────┐\n",
       "│ epoch ┆ Accuracy ┆ Balanced Accuracy ┆ Precision ┆ … ┆ tn    ┆ fp    ┆ fn   ┆ tp     │\n",
       "│ ---   ┆ ---      ┆ ---               ┆ ---       ┆   ┆ ---   ┆ ---   ┆ ---  ┆ ---    │\n",
       "│ i64   ┆ f64      ┆ f64               ┆ f64       ┆   ┆ i64   ┆ i64   ┆ i64  ┆ i64    │\n",
       "╞═══════╪══════════╪═══════════════════╪═══════════╪═══╪═══════╪═══════╪══════╪════════╡\n",
       "│ 1     ┆ 0.839677 ┆ 0.5               ┆ 0.839677  ┆ … ┆ 0     ┆ 26705 ┆ 0    ┆ 139865 │\n",
       "│ 2     ┆ 0.839677 ┆ 0.5               ┆ 0.839677  ┆ … ┆ 0     ┆ 26705 ┆ 0    ┆ 139865 │\n",
       "│ 3     ┆ 0.839677 ┆ 0.5               ┆ 0.839677  ┆ … ┆ 0     ┆ 26705 ┆ 0    ┆ 139865 │\n",
       "│ 4     ┆ 0.980657 ┆ 0.961472          ┆ 0.987283  ┆ … ┆ 24922 ┆ 1783  ┆ 1439 ┆ 138426 │\n",
       "│ 5     ┆ 0.977241 ┆ 0.959681          ┆ 0.987343  ┆ … ┆ 24938 ┆ 1767  ┆ 2024 ┆ 137841 │\n",
       "│ 6     ┆ 0.976869 ┆ 0.959414          ┆ 0.987317  ┆ … ┆ 24935 ┆ 1770  ┆ 2083 ┆ 137782 │\n",
       "└───────┴──────────┴───────────────────┴───────────┴───┴───────┴───────┴──────┴────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pl.DataFrame(\n",
    "    results,\n",
    "    schema=['epoch', 'Accuracy', 'Balanced Accuracy', 'Precision', 'Recall', 'Specificity', 'F1-score', 'False Alarm Rate', 'tn', 'fp', 'fn', 'tp']\n",
    ")\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
