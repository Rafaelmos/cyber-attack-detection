{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = ['CTU-Honeypot-Capture-4-1','CTU-Honeypot-Capture-5-1','CTU-Honeypot-Capture-7-1', #2\n",
    "         'CTU-IoT-Malware-Capture-1-1','CTU-IoT-Malware-Capture-3-1','CTU-IoT-Malware-Capture-7-1',#5\n",
    "         'CTU-IoT-Malware-Capture-8-1','CTU-IoT-Malware-Capture-9-1','CTU-IoT-Malware-Capture-20-1',#8\n",
    "         'CTU-IoT-Malware-Capture-21-1','CTU-IoT-Malware-Capture-34-1','CTU-IoT-Malware-Capture-35-1',#11\n",
    "         'CTU-IoT-Malware-Capture-36-1','CTU-IoT-Malware-Capture-42-1','CTU-IoT-Malware-Capture-44-1', #14\n",
    "         'CTU-IoT-Malware-Capture-48-1','CTU-IoT-Malware-Capture-49-1','CTU-IoT-Malware-Capture-60-1',] #17\n",
    "\n",
    "caminhos_arquivos = [f'../../{nome_arquivo}.parquet' for nome_arquivo in lista]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [dd.read_parquet(caminho, engine='pyarrow') for caminho in caminhos_arquivos]\n",
    "df = dd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(frac=0.01, random_state=42)\n",
    "del lista, dfs,caminhos_arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para substituir \"-\" por \"0\" em uma coluna\n",
    "def replace_dash_with_zero_dask(df, column):\n",
    "    df[column] = df[column].replace(\"-\", \"0\", regex=True)\n",
    "    return df\n",
    "\n",
    "# Aplicar a substituição nas colunas desejadas\n",
    "df = df.map_partitions(replace_dash_with_zero_dask, column='duration')\n",
    "df = df.map_partitions(replace_dash_with_zero_dask, column='orig_bytes')\n",
    "df = df.map_partitions(replace_dash_with_zero_dask, column='resp_bytes')\n",
    "\n",
    "# Conversão de tipos\n",
    "df['ts'] = df['ts'].astype(float)\n",
    "df['uid'] = df['uid'].astype(str)\n",
    "df['id.orig_h'] = df['id.orig_h'].astype(str)\n",
    "df['id.orig_p'] = df['id.orig_p'].astype(int)\n",
    "df['id.resp_h'] = df['id.resp_h'].astype(str)\n",
    "df['id.resp_p'] = df['id.resp_p'].astype(int)\n",
    "df['proto'] = df['proto'].astype(str)\n",
    "df['service'] = df['service'].astype(str)\n",
    "df['duration'] = df['duration'].astype(float)\n",
    "df['orig_bytes'] = df['orig_bytes'].astype(float)\n",
    "df['resp_bytes'] = df['resp_bytes'].astype(float)\n",
    "df['conn_state'] = df['conn_state'].astype(str)\n",
    "df['local_orig'] = df['local_orig'].astype(str)\n",
    "df['local_resp'] = df['local_resp'].astype(str)\n",
    "df['missed_bytes'] = df['missed_bytes'].astype(int)\n",
    "df['history'] = df['history'].astype(str)\n",
    "df['tunnel_parents'] = df['tunnel_parents'].astype(str)\n",
    "df['label'] = df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear labels\n",
    "df['label'] = df['label'].str.replace('benign', 'Benign')\n",
    "df['label'] = df['label'].map({'Benign': 0, 'Malicious': 1})\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['proto', 'service', 'conn_state', 'history']\n",
    "\n",
    "def label_encode_column(df, col):\n",
    "    unique_values = df[col].dropna().unique()\n",
    "    label_mapping = {value: i for i, value in enumerate(unique_values)}\n",
    "    df[col] = df[col].map(label_mapping)\n",
    "    return df\n",
    "\n",
    "for col in label_columns:\n",
    "    df = df.map_partitions(label_encode_column, col=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars = pl.from_pandas(pandas_df)\n",
    "\n",
    "del pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polars.write_parquet('dataset.parquet', compression='snappy')\n",
    "print(f\"Arquivo foi salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arquivo = \"dataset\"\n",
    "#df_pandas.to_parquet(f'{arquivo}.parquet', compression='snappy')\n",
    "\n",
    "#print(f\"Arquivo '{arquivo}.parquet' salvo com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
